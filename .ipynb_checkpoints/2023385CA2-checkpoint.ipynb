{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652dcaa1",
   "metadata": {},
   "source": [
    "# TIME SERIES FORECASTING AND SENTIMENT ANALYSIS OF BIG DATA PROOCESSED WITH MYSQL VS HBASE, CASSANDRA, MONGODB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485163c",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "The dataste is a large dataset gleaned from the twitter API that is called ProjectTweets.csv.\n",
    "\n",
    "This dataset contains 1,600,000 tweets extracted using the twitter api. \n",
    "\n",
    "\n",
    "Content\n",
    "It contains the following 5 fields:\n",
    "- ids: The id of the tweet (eg. 4587)\n",
    "- date: the date of the tweet (eg. Sat May 16 23:58:44 UTC 2009)\n",
    "- flag: The query (eg. lyx). If there is no query, then this value is NO_QUERY.\n",
    "- user: the user that tweeted (eg. bobthebuilder)\n",
    "- text: the text of the tweet (eg. Lyx is cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cb3bd8",
   "metadata": {},
   "source": [
    "# Storing Data in a SQL vs Non SQL Database\n",
    "- MySQL\n",
    "- Hbase\n",
    "- Cassandra\n",
    "- MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7365c",
   "metadata": {},
   "source": [
    "# MySQL via Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf7c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"Load CSV to MySQL\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22310d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame\n",
    "csv_path = \"file:///home/hduser/ProjectTweets/ProjectTweets.csv\"\n",
    "df = spark.read.csv(csv_path, header=False, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7df056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2600f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"_c0\", \"ID\").withColumnRenamed(\"_c1\", \"ID2\").withColumnRenamed(\"_c2\", \"date\").withColumnRenamed(\"_c3\", \"flag\").withColumnRenamed(\"_c4\", \"user\").withColumnRenamed(\"_c5\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272db695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the Spark DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe671f4",
   "metadata": {},
   "source": [
    "# Storing and Processing Data in MySQL using pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971be961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define JDBC connection properties\n",
    "mysql_properties = {\n",
    "    \"driver\": \"com.mysql.jdbc.Driver\",\n",
    "    \"url\": \"jdbc:mysql://localhost:3306/ProjectTweets\",\n",
    "    \"user\": \"hduser\",\n",
    "    \"password\": \"hadoop\"\n",
    "}\n",
    "\n",
    "# Define MySQL table name\n",
    "mysql_table_name = \"ProjectTweets\"\n",
    "\n",
    "# Read CSV file into DataFrame\n",
    "csv_path = \"file:///home/hduser/ProjectTweets.csv\"\n",
    "df = sc.read.csv(csv_path, header=False, inferSchema=True)\n",
    "\n",
    "# Write DataFrame to MySQL table\n",
    "df.write.jdbc(url=mysql_properties[\"url\"],\n",
    "              table=mysql_table_name,\n",
    "              mode=\"overwrite\",  # Specify the write mode\n",
    "              properties=mysql_properties)\n",
    "\n",
    "# Stop SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603f5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
