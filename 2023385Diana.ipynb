{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a691eb-491c-4cbd-acfd-363055534da4",
   "metadata": {},
   "source": [
    "# TIME SERIES FORECASTING OF PROJECT TWEETS BIG DATA PROCESSED WITH SPARK AND STORED IN MONGODB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cf4c2b-41fe-4f80-a139-066374224315",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "The dataste is a large dataset gleaned from the twitter API that is called ProjectTweets.csv.\n",
    "\n",
    "This dataset contains 1,600,000 tweets extracted using the twitter api. \n",
    "\n",
    "\n",
    "Content\n",
    "It contains the following 5 fields:\n",
    "- ids: The id of the tweet (eg. 4587)\n",
    "- date: the date of the tweet (eg. Sat May 16 23:58:44 UTC 2009)\n",
    "- flag: The query (eg. lyx). If there is no query, then this value is NO_QUERY.\n",
    "- user: the user that tweeted (eg. bobthebuilder)\n",
    "- text: the text of the tweet (eg. Lyx is cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c402ab-f73e-44fa-9bcb-3cd3686a1d6e",
   "metadata": {},
   "source": [
    "## Install all Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a43f76-594a-4b56-88e2-fa2bb26f45cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import all necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.functions import col, lower, regexp_replace, trim, split, udf\n",
    "from pyspark.sql.functions import isnull, to_timestamp\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.types import StructType, StringType, TimestampType\n",
    "from pyspark.sql.functions import col\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # We can suppress the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7dfddb-3db1-4417-8904-25e89ff1daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a pyspark session connecting to mongodb\n",
    "uri = \"mongodb://172.17.0.8:27017/DeeProject_mongo.Tweets\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Write into MongoDB\")\\\n",
    "    .config(\"spark.mongodb.input.uri\", uri)\\\n",
    "    .config(\"spark.mongodb.output.uri\", uri)\\\n",
    "    .config('spark.jars.packages','org.mongodb.spark:mongo-spark-connector_2.12:2.4.2')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b77330-d443-4ce3-b6c4-2dd938b1284c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://4dde10a4171c:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Write into MongoDB</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff7a1e4bd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spark content\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f184ca6-02a1-49d4-9e34-39b94abba76b",
   "metadata": {},
   "source": [
    "# Step one: Writing Data into MongoDB using Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31398c42-136d-4ff4-b665-0932e06a61f7",
   "metadata": {},
   "source": [
    "## Loading data from local machine to SParkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55462fc4-56f4-4222-a185-b00572045103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PRIMARY KEY: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+-----------+----------+-------------------+--------+---------------+--------------------+\n",
      "|PRIMARY KEY|        ID|               date|    flag|           user|                text|\n",
      "+-----------+----------+-------------------+--------+---------------+--------------------+\n",
      "|          0|1467810369|2009-04-07 05:19:45|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|          1|1467810672|2009-04-07 05:19:49|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|          2|1467810917|2009-04-07 05:19:53|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|          3|1467811184|2009-04-07 05:19:57|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|          4|1467811193|2009-04-07 05:19:57|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "+-----------+----------+-------------------+--------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Set legacy timeParserPolicy\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "#Define the schema for the csv file \n",
    "schema = StructType().add(\"_c0\", StringType(), True).add(\"_c1\", StringType(), True).add(\"_c2\", StringType(), True).add(\"_c3\", StringType(), True).add(\"_c4\", StringType(), True).add(\"_c5\", StringType(), True)\n",
    "\n",
    "#Read the CSV into a DataFrame called df\n",
    "df = spark.read.format(\"csv\").option(\"header\", False).schema(schema).load(\"file:///home/jovyan/Diana/ProjectTweets.csv\")\n",
    "\n",
    "#Rename the headers\n",
    "df = df.withColumnRenamed(\"_c0\", \"PRIMARY KEY\").withColumnRenamed(\"_c1\", \"ID\").withColumnRenamed(\"_c2\", \"date\").withColumnRenamed(\"_c3\", \"flag\").withColumnRenamed(\"_c4\", \"user\").withColumnRenamed(\"_c5\", \"text\")\n",
    "\n",
    "#Convert string date to TimestampType\n",
    "df = df.withColumn(\"date\", to_timestamp(df[\"date\"], \"EEE MMM dd HH:mm:ss zzzz yyyy\"))\n",
    "\n",
    "#Print schema\n",
    "df.printSchema()\n",
    "\n",
    "#Show DataFrame\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566df067-a314-47b2-a4a4-ca03159f58c0",
   "metadata": {},
   "source": [
    "## Write data from spark to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25ea7c1-ebd1-4d4a-88d9-a03a091d224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write data into MongoDB\n",
    "df.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").option(\"uri\", uri).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1058c99-28db-47dd-9276-f51419737644",
   "metadata": {},
   "source": [
    "# Step Two: Read the Project Tweets data from MongoDB using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e81c22-f29d-45c9-98bf-f2dcc2585c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 7)\n",
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- PRIMARY KEY: string (nullable = true)\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      "\n",
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+\n",
      "|        ID|PRIMARY KEY|                 _id|               date|    flag|                text|         user|\n",
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+\n",
      "|1551363506|     816210|{66367bb0e048fa3c...|2009-04-18 15:51:40|NO_QUERY|@ctribe I hope yo...|prosario_2000|\n",
      "|2059493951|     408810|{66367bb0e048fa3c...|2009-06-07 00:02:45|NO_QUERY|Kinda scared to s...|        l7l7v|\n",
      "|1990436550|    1223636|{66367bb0e048fa3c...|2009-06-01 11:52:03|NO_QUERY|@karinhoegh  Didn...|         kmdk|\n",
      "|1990436582|    1223637|{66367bb0e048fa3c...|2009-06-01 11:52:03|NO_QUERY|Need more FPS.......| jflinchbaugh|\n",
      "|1990436614|    1223638|{66367bb0e048fa3c...|2009-06-01 11:52:04|NO_QUERY|@SteveOGallagher ...|    kittaykat|\n",
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read Data from MongoDB\n",
    "from_mongo = spark.read.format('com.mongodb.spark.sql.DefaultSource').load()\n",
    "print((from_mongo.count(), len(from_mongo.columns)))\n",
    "from_mongo.printSchema()\n",
    "from_mongo.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e3bdf-eed2-442b-815b-bf2375d0c84d",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fbf0a7-9366-41bc-9a1b-bff77cf5d2db",
   "metadata": {},
   "source": [
    "# Checking for Duplicates (based on ID, user and text) and Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "187c1a83-e90c-4eff-8310-967d2c6c62b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records removed: 0\n",
      "Missing value counts:\n",
      "PRIMARY KEY 0\n",
      "ID 0\n",
      "user 0\n",
      "text 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum  # Import the 'col' and 'sum' functions\n",
    "\n",
    "#Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Duplicate and Missing Data Check\").getOrCreate()\n",
    "\n",
    "#Define the columns to check for duplicates and missing values\n",
    "columns_to_check = ['PRIMARY KEY','ID', 'user', 'text']\n",
    "\n",
    "#Create a pipeline to check for duplicates and missing values\n",
    "pipeline_df = from_mongo\n",
    "\n",
    "#Step 1: Remove duplicate records based on specified columns\n",
    "pipeline_df = pipeline_df.dropDuplicates(subset=columns_to_check)\n",
    "\n",
    "#Step 2: Check for missing values\n",
    "missing_counts = pipeline_df.select([col(c).isNull().cast(\"int\").alias(c) for c in columns_to_check]).agg(*[sum(c).alias(c) for c in columns_to_check]).collect()[0]\n",
    "\n",
    "#Print the results\n",
    "print(\"Number of duplicate records removed:\", df.count() - pipeline_df.count())\n",
    "\n",
    "print(\"Missing value counts:\")\n",
    "for col_name, missing_count in zip(columns_to_check, missing_counts):\n",
    "    print(col_name, missing_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed96930b-c1ab-4e9a-bad7-0ba5b186de0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "#Checking for duplicates in ID and user name\n",
    "#Count the number of rows before removing duplicates\n",
    "count_before = from_mongo.count()\n",
    "\n",
    "#Remove duplicates\n",
    "df_no_duplicates = from_mongo.dropDuplicates()\n",
    "\n",
    "#Count the number of rows after removing duplicates\n",
    "count_after = df_no_duplicates.count()\n",
    "\n",
    "#Calculate the number of duplicates\n",
    "num_duplicates = count_before - count_after\n",
    "\n",
    "print(f\"Number of duplicate rows removed: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a932d2b7-a0b9-484a-8374-24873e591aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows removed based on user: 940225\n"
     ]
    }
   ],
   "source": [
    "#Count the number of rows before removing duplicates\n",
    "count_before = from_mongo.count()\n",
    "\n",
    "#Remove duplicates based on a specific column\n",
    "df_no_duplicates = from_mongo.dropDuplicates(subset=['user'])\n",
    "\n",
    "#Count the number of rows after removing duplicates\n",
    "count_after = df_no_duplicates.count()\n",
    "\n",
    "#Calculate the number of duplicates\n",
    "num_duplicates = count_before - count_after\n",
    "\n",
    "print(f\"Number of duplicate rows removed based on user: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c5cba-92d8-401f-b90a-a9d692beaef9",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ede2aa7-cdb7-4e5e-b464-2ec6a84f41f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+--------+--------------------+--------------------+\n",
      "|summary|                  ID|       PRIMARY KEY|    flag|                text|                user|\n",
      "+-------+--------------------+------------------+--------+--------------------+--------------------+\n",
      "|  count|             1600000|           1600000| 1600000|             1600000|             1600000|\n",
      "|   mean|1.9988175522956276E9|          799999.5|    NULL|                NULL| 4.325887521835714E9|\n",
      "| stddev|1.9357607362267783E8|461880.35968924506|    NULL|                NULL|5.162733218454889E10|\n",
      "|    min|          1467810369|                 0|NO_QUERY|                 ...|        000catnap000|\n",
      "|    max|          2329205794|            999999|NO_QUERY|ï¿½ï¿½ï¿½ï¿½ï¿½ß§...|          zzzzeus111|\n",
      "+-------+--------------------+------------------+--------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Summary Statistics\n",
    "from_mongo.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0434c55c-c286-4dc3-808d-2238fe7857aa",
   "metadata": {},
   "source": [
    "# EXTRACTING TIME COMPONENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe21863a-1658-407e-911a-1fda5e8dde90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, hour, minute, second\n",
    "\n",
    "\n",
    "#Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"DateTime Visualization\").getOrCreate()\n",
    "\n",
    "#Extract relevant time components including hours, minutes, and seconds\n",
    "df = from_mongo.withColumn(\"year\", year(\"date\")).withColumn(\"month\", month(\"date\")).withColumn(\"day\", dayofmonth(\"date\")).withColumn(\"hour\", hour(\"date\")).withColumn(\"minute\", minute(\"date\")).withColumn(\"second\", second(\"date\"))\n",
    "\n",
    "#Aggregate data\n",
    "time_series_data = df.groupBy(\"date\",\"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\").count().orderBy(\"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6abfb12d-a4e9-42f9-a369-0da22a65198c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+----+-----+---+----+------+------+\n",
      "|        ID|PRIMARY KEY|                 _id|               date|    flag|                text|         user|year|month|day|hour|minute|second|\n",
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+----+-----+---+----+------+------+\n",
      "|1551363506|     816210|{66367bb0e048fa3c...|2009-04-18 15:51:40|NO_QUERY|@ctribe I hope yo...|prosario_2000|2009|    4| 18|  15|    51|    40|\n",
      "|2059493951|     408810|{66367bb0e048fa3c...|2009-06-07 00:02:45|NO_QUERY|Kinda scared to s...|        l7l7v|2009|    6|  7|   0|     2|    45|\n",
      "|1990436550|    1223636|{66367bb0e048fa3c...|2009-06-01 11:52:03|NO_QUERY|@karinhoegh  Didn...|         kmdk|2009|    6|  1|  11|    52|     3|\n",
      "|1990436582|    1223637|{66367bb0e048fa3c...|2009-06-01 11:52:03|NO_QUERY|Need more FPS.......| jflinchbaugh|2009|    6|  1|  11|    52|     3|\n",
      "|1990436614|    1223638|{66367bb0e048fa3c...|2009-06-01 11:52:04|NO_QUERY|@SteveOGallagher ...|    kittaykat|2009|    6|  1|  11|    52|     4|\n",
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+----+-----+---+----+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View the df DataFrame after extracting time components\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f5ddeaa-d79e-4072-bc25-b5a199762d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- PRIMARY KEY: string (nullable = true)\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- minute: integer (nullable = true)\n",
      " |-- second: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View the Spark DataFrame Features\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bdc1db1-372d-4a9c-b0d6-f349f16c28d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|year|  count|\n",
      "+----+-------+\n",
      "|2009|1600000|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "#Group by the year variable and count the occurrences\n",
    "year_counts = df.groupBy(\"year\").agg(count(\"*\").alias(\"count\")).orderBy(\"year\")\n",
    "\n",
    "#Show the tabulated counts\n",
    "year_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fd43d47-9889-4b8a-bd4c-0d21769af583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|month| count|\n",
      "+-----+------+\n",
      "|    4|100025|\n",
      "|    5|559073|\n",
      "|    6|940902|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "#Group by the month variable and count the occurrences\n",
    "month_counts = df.groupBy(\"month\").agg(count(\"*\").alias(\"count\")).orderBy(\"month\")\n",
    "\n",
    "#Show the tabulated counts\n",
    "month_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf0b81c-185e-4e34-9015-bfa8daf9ff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|day| count|\n",
      "+---+------+\n",
      "|  1| 95449|\n",
      "|  2|108872|\n",
      "|  3| 86707|\n",
      "|  4| 32938|\n",
      "|  5| 34735|\n",
      "|  6|104793|\n",
      "|  7|132564|\n",
      "|  8| 18566|\n",
      "| 10| 31551|\n",
      "| 11|  6217|\n",
      "| 12|  4186|\n",
      "| 14| 22026|\n",
      "| 15| 83309|\n",
      "| 16| 87524|\n",
      "| 17| 85236|\n",
      "| 18|105040|\n",
      "| 19| 75612|\n",
      "| 20| 64029|\n",
      "| 21| 41782|\n",
      "| 22| 49519|\n",
      "+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "#Group by the day variable and count the occurrences\n",
    "day_counts = df.groupBy(\"day\").agg(count(\"*\").alias(\"count\")).orderBy(\"day\")\n",
    "\n",
    "#Show the tabulated counts\n",
    "day_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b299e87-f152-4d96-8ccb-4e2d086352a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "|month|day| count|\n",
      "+-----+---+------+\n",
      "|    4|  7| 20671|\n",
      "|    4| 18| 17154|\n",
      "|    4| 20| 18447|\n",
      "|    4| 21| 11105|\n",
      "|    4| 19| 32648|\n",
      "|    5|  4| 28300|\n",
      "|    5| 10| 31551|\n",
      "|    5|  2| 31096|\n",
      "|    5|  3| 26568|\n",
      "|    5| 22| 41206|\n",
      "|    5| 24|   169|\n",
      "|    5| 17| 41205|\n",
      "|    5| 12|  4186|\n",
      "|    5| 29| 60227|\n",
      "|    5| 18| 44564|\n",
      "|    5| 27| 11619|\n",
      "|    5| 11|  6217|\n",
      "|    5| 14| 21526|\n",
      "|    5| 25|   169|\n",
      "|    5| 30|104484|\n",
      "+-----+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Group by the day variable and count the occurrences\n",
    "day_counts = df.groupBy(\"month\",\"day\").agg(count(\"*\").alias(\"count\")).orderBy(\"month\")\n",
    "\n",
    "# Show the tabulated counts\n",
    "day_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "541597f2-d4a9-4ad7-926d-ac1e9143e010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|        ID|count|\n",
      "+----------+-----+\n",
      "|1467810369|    1|\n",
      "|1467810672|    1|\n",
      "|1467810917|    1|\n",
      "|1467811184|    1|\n",
      "|1467811193|    1|\n",
      "|1467811372|    1|\n",
      "|1467811592|    1|\n",
      "|1467811594|    1|\n",
      "|1467811795|    1|\n",
      "|1467812025|    1|\n",
      "|1467812416|    1|\n",
      "|1467812579|    1|\n",
      "|1467812723|    1|\n",
      "|1467812771|    1|\n",
      "|1467812784|    1|\n",
      "|1467812799|    1|\n",
      "|1467812964|    1|\n",
      "|1467813137|    1|\n",
      "|1467813579|    1|\n",
      "|1467813782|    1|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Group by the day variable and count the occurrences\n",
    "ID_counts = df.groupBy(\"ID\").agg(count(\"*\").alias(\"count\")).orderBy(\"ID\")\n",
    "\n",
    "# Show the tabulated counts\n",
    "ID_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aa8b6aa-5236-4a88-a720-4bf30e7efac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-----+---+----+------+------+-----+\n",
      "|               date|year|month|day|hour|minute|second|count|\n",
      "+-------------------+----+-----+---+----+------+------+-----+\n",
      "|2009-04-07 05:19:45|2009|    4|  7|   5|    19|    45|    1|\n",
      "|2009-04-07 05:19:49|2009|    4|  7|   5|    19|    49|    1|\n",
      "|2009-04-07 05:19:53|2009|    4|  7|   5|    19|    53|    1|\n",
      "|2009-04-07 05:19:57|2009|    4|  7|   5|    19|    57|    2|\n",
      "|2009-04-07 05:20:00|2009|    4|  7|   5|    20|     0|    1|\n",
      "+-------------------+----+-----+---+----+------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_series_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e106b132-eff5-43bf-a5d7-8d8d313cff17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(time_series_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b7a2cf6-988e-4f0d-8c95-b9e8af71d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+----+-----+---+----+------+------+\n",
      "|        ID|PRIMARY KEY|                 _id|               date|    flag|                text|         user|year|month|day|hour|minute|second|\n",
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+----+-----+---+----+------+------+\n",
      "|1551363506|     816210|{66367bb0e048fa3c...|2009-04-18 15:51:40|NO_QUERY|@ctribe I hope yo...|prosario_2000|2009|    4| 18|  15|    51|    40|\n",
      "|2059493951|     408810|{66367bb0e048fa3c...|2009-06-07 00:02:45|NO_QUERY|Kinda scared to s...|        l7l7v|2009|    6|  7|   0|     2|    45|\n",
      "|1990436550|    1223636|{66367bb0e048fa3c...|2009-06-01 11:52:03|NO_QUERY|@karinhoegh  Didn...|         kmdk|2009|    6|  1|  11|    52|     3|\n",
      "|1990436582|    1223637|{66367bb0e048fa3c...|2009-06-01 11:52:03|NO_QUERY|Need more FPS.......| jflinchbaugh|2009|    6|  1|  11|    52|     3|\n",
      "|1990436614|    1223638|{66367bb0e048fa3c...|2009-06-01 11:52:04|NO_QUERY|@SteveOGallagher ...|    kittaykat|2009|    6|  1|  11|    52|     4|\n",
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+----+-----+---+----+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5363f5b-5885-4097-8cb6-05ee4d0bea80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "888f4542-a27e-4089-b039-42b85b778464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+----+-----+---+----+------+------+\n",
      "|        ID|PRIMARY KEY|                 _id|               date|    flag|                text|         user|year|month|day|hour|minute|second|\n",
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+----+-----+---+----+------+------+\n",
      "|1551363506|     816210|{66367bb0e048fa3c...|2009-04-18 15:51:40|NO_QUERY|@ctribe I hope yo...|prosario_2000|2009|    4| 18|  15|    51|    40|\n",
      "|2059493951|     408810|{66367bb0e048fa3c...|2009-06-07 00:02:45|NO_QUERY|Kinda scared to s...|        l7l7v|2009|    6|  7|   0|     2|    45|\n",
      "|1990436550|    1223636|{66367bb0e048fa3c...|2009-06-01 11:52:03|NO_QUERY|@karinhoegh  Didn...|         kmdk|2009|    6|  1|  11|    52|     3|\n",
      "|1990436582|    1223637|{66367bb0e048fa3c...|2009-06-01 11:52:03|NO_QUERY|Need more FPS.......| jflinchbaugh|2009|    6|  1|  11|    52|     3|\n",
      "|1990436614|    1223638|{66367bb0e048fa3c...|2009-06-01 11:52:04|NO_QUERY|@SteveOGallagher ...|    kittaykat|2009|    6|  1|  11|    52|     4|\n",
      "+----------+-----------+--------------------+-------------------+--------+--------------------+-------------+----+-----+---+----+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c454c80-e4e2-4dc9-aa0a-24c70f313ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"_id\", \"ID\", \"PRIMARY KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31d4a827-9c5c-40f1-ac43-113524c40842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------------------+---------------+----+-----+---+----+------+------+\n",
      "|               date|    flag|                text|           user|year|month|day|hour|minute|second|\n",
      "+-------------------+--------+--------------------+---------------+----+-----+---+----+------+------+\n",
      "|2009-04-18 15:51:40|NO_QUERY|@ctribe I hope yo...|  prosario_2000|2009|    4| 18|  15|    51|    40|\n",
      "|2009-06-07 00:02:45|NO_QUERY|Kinda scared to s...|          l7l7v|2009|    6|  7|   0|     2|    45|\n",
      "|2009-06-01 11:52:03|NO_QUERY|@karinhoegh  Didn...|           kmdk|2009|    6|  1|  11|    52|     3|\n",
      "|2009-06-01 11:52:03|NO_QUERY|Need more FPS.......|   jflinchbaugh|2009|    6|  1|  11|    52|     3|\n",
      "|2009-06-01 11:52:04|NO_QUERY|@SteveOGallagher ...|      kittaykat|2009|    6|  1|  11|    52|     4|\n",
      "|2009-04-18 15:51:39|NO_QUERY|@Boy_Kill_Boy Nop...|Chelsea_Volturi|2009|    4| 18|  15|    51|    39|\n",
      "|2009-06-01 11:52:04|NO_QUERY|Can't wait for th...|          Mm_Ka|2009|    6|  1|  11|    52|     4|\n",
      "|2009-06-01 11:52:04|NO_QUERY|@nickayre Lol. Bu...|    bryancheung|2009|    6|  1|  11|    52|     4|\n",
      "|2009-06-01 11:52:05|NO_QUERY|I love it when I ...|      videohive|2009|    6|  1|  11|    52|     5|\n",
      "|2009-04-18 15:51:41|NO_QUERY|@marty0518 Someti...|askbillmitchell|2009|    4| 18|  15|    51|    41|\n",
      "|2009-06-01 11:52:05|NO_QUERY|http://twitpic.co...|     kayepintac|2009|    6|  1|  11|    52|     5|\n",
      "|2009-04-18 15:51:41|NO_QUERY|so i guesss im no...|       kendiixd|2009|    4| 18|  15|    51|    41|\n",
      "|2009-06-01 11:52:05|NO_QUERY|@STARBUCK_NOLA Wh...|     Dayewalker|2009|    6|  1|  11|    52|     5|\n",
      "|2009-04-18 15:51:42|NO_QUERY|@DaiLS I do that,...|    ladycalypso|2009|    4| 18|  15|    51|    42|\n",
      "|2009-06-01 11:52:06|NO_QUERY|Taking down the t...|          padrg|2009|    6|  1|  11|    52|     6|\n",
      "|2009-04-18 15:51:43|NO_QUERY|trendy topic - Re...| FindingAnswers|2009|    4| 18|  15|    51|    43|\n",
      "|2009-06-01 11:52:06|NO_QUERY|@Jon_W_Turner i k...| electronichaze|2009|    6|  1|  11|    52|     6|\n",
      "|2009-04-18 15:51:43|NO_QUERY|@firsttiger Real ...|      HTwashere|2009|    4| 18|  15|    51|    43|\n",
      "|2009-06-01 11:52:08|NO_QUERY|@freshleafdesign ...|  runwaycrochet|2009|    6|  1|  11|    52|     8|\n",
      "|2009-04-18 15:51:43|NO_QUERY|@Dragoncade I see...|     kelliekano|2009|    4| 18|  15|    51|    43|\n",
      "+-------------------+--------+--------------------+---------------+----+-----+---+----+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adcd709",
   "metadata": {},
   "source": [
    "## Save the df Dataframe as a Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1c79181-cf3f-4a96-b13e-250d46b8f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5f72732-7fb8-4d2b-a717-1089f13a4928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#Create pandas DataFrame from the list of rows\n",
    "pandas_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c0a3de3-5f9d-460b-9c03-1323dc5d9352",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df.columns = df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79d6ea32-f739-4923-8a77-e21fdb1bca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00fec948-c900-4408-81a4-1c31dd2017d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file path where you want to save the CSV file\n",
    "file_path = \"pandas_data.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "pandas_df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cea26",
   "metadata": {},
   "source": [
    "# Save the processed Data to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7aa9eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write data into MongoDB\n",
    "df.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").option(\"uri\", uri).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f115c9",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS COMPARING VADER VS TEXTBLOB, THEN TIME SERIES FORECASTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366ebf1",
   "metadata": {},
   "source": [
    "## Text/Tweets Processing\n",
    "This includes the following steps:-\n",
    "- Read and Load the Dataset\n",
    "- Exploratory Data Analysis\n",
    "- Data Visualization of Target Variables\n",
    "- Data Preprocessing\n",
    "- Splitting our data into Train and Test sets.\n",
    "- Transforming Dataset using TF-IDF Vectorizer\n",
    "- Function for Model Evaluation\n",
    "- Model Building\n",
    "- Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf8399d",
   "metadata": {},
   "source": [
    "# Read the  pandas_data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd2b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load the data\n",
    "df = pd.read_csv(\"C:/Users/Diana/Documents/Semester 2/sem two ca 2/pandas_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc43617",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "This process involves:-\n",
    "\n",
    "a) View the first and last few observations of the df dataframe\n",
    "\n",
    "b) View the number of observations and variables the df dataframe has\n",
    "\n",
    "c) View the entire df dataframe to check the data types and any missing data in a particluar variable.\n",
    " \n",
    "d) Checking for missing data/dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf1a946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-18 15:51:40</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>@ctribe I hope you are having a great day.</td>\n",
       "      <td>prosario_2000</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-06-07 00:02:45</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Kinda scared to sleep alone in this house toni...</td>\n",
       "      <td>l7l7v</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-06-01 11:52:03</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>@karinhoegh  Didn't think of national holidays...</td>\n",
       "      <td>kmdk</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2009-06-01 11:52:03</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Need more FPS....time to shop for a new camera...</td>\n",
       "      <td>jflinchbaugh</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2009-06-01 11:52:04</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>@SteveOGallagher take me with u</td>\n",
       "      <td>kittaykat</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 date      flag  \\\n",
       "0           0  2009-04-18 15:51:40  NO_QUERY   \n",
       "1           1  2009-06-07 00:02:45  NO_QUERY   \n",
       "2           2  2009-06-01 11:52:03  NO_QUERY   \n",
       "3           3  2009-06-01 11:52:03  NO_QUERY   \n",
       "4           4  2009-06-01 11:52:04  NO_QUERY   \n",
       "\n",
       "                                                text           user  year  \\\n",
       "0        @ctribe I hope you are having a great day.   prosario_2000  2009   \n",
       "1  Kinda scared to sleep alone in this house toni...          l7l7v  2009   \n",
       "2  @karinhoegh  Didn't think of national holidays...           kmdk  2009   \n",
       "3  Need more FPS....time to shop for a new camera...   jflinchbaugh  2009   \n",
       "4                   @SteveOGallagher take me with u       kittaykat  2009   \n",
       "\n",
       "   month  day  hour  minute  second  \n",
       "0      4   18    15      51      40  \n",
       "1      6    7     0       2      45  \n",
       "2      6    1    11      52       3  \n",
       "3      6    1    11      52       3  \n",
       "4      6    1    11      52       4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the first few observations of the df DataFrame\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c71c35ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>1599995</td>\n",
       "      <td>2009-06-07 00:02:36</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>I just got a bunch of money for graduation, bu...</td>\n",
       "      <td>chichi7391</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>1599996</td>\n",
       "      <td>2009-06-07 00:02:40</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>were is my pic</td>\n",
       "      <td>lambrinilesley</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>1599997</td>\n",
       "      <td>2009-06-07 00:02:41</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>@sar_88 you had to wait 2 hours for the foood</td>\n",
       "      <td>sweetmash</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>1599998</td>\n",
       "      <td>2009-06-07 00:02:41</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>@pollyyy by the way i hate you for seeing bran...</td>\n",
       "      <td>LittleBirkett</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>1599999</td>\n",
       "      <td>2009-06-07 00:02:41</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Not looking forward to a good 9 hours at One P...</td>\n",
       "      <td>paul_hauffe</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                 date      flag  \\\n",
       "1599995     1599995  2009-06-07 00:02:36  NO_QUERY   \n",
       "1599996     1599996  2009-06-07 00:02:40  NO_QUERY   \n",
       "1599997     1599997  2009-06-07 00:02:41  NO_QUERY   \n",
       "1599998     1599998  2009-06-07 00:02:41  NO_QUERY   \n",
       "1599999     1599999  2009-06-07 00:02:41  NO_QUERY   \n",
       "\n",
       "                                                      text            user  \\\n",
       "1599995  I just got a bunch of money for graduation, bu...      chichi7391   \n",
       "1599996                                    were is my pic   lambrinilesley   \n",
       "1599997     @sar_88 you had to wait 2 hours for the foood        sweetmash   \n",
       "1599998  @pollyyy by the way i hate you for seeing bran...   LittleBirkett   \n",
       "1599999  Not looking forward to a good 9 hours at One P...     paul_hauffe   \n",
       "\n",
       "         year  month  day  hour  minute  second  \n",
       "1599995  2009      6    7     0       2      36  \n",
       "1599996  2009      6    7     0       2      40  \n",
       "1599997  2009      6    7     0       2      41  \n",
       "1599998  2009      6    7     0       2      41  \n",
       "1599999  2009      6    7     0       2      41  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the last few observations of the df DataFrame\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d5967b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the shape of the df DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d032ff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Unnamed: 0  1600000 non-null  int64 \n",
      " 1   date        1600000 non-null  object\n",
      " 2   flag        1600000 non-null  object\n",
      " 3   text        1600000 non-null  object\n",
      " 4   user        1600000 non-null  object\n",
      " 5   year        1600000 non-null  int64 \n",
      " 6   month       1600000 non-null  int64 \n",
      " 7   day         1600000 non-null  int64 \n",
      " 8   hour        1600000 non-null  int64 \n",
      " 9   minute      1600000 non-null  int64 \n",
      " 10  second      1600000 non-null  int64 \n",
      "dtypes: int64(7), object(4)\n",
      "memory usage: 134.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#View the features\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0880a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date_column' to datetime datatype\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3da2837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count    Dtype         \n",
      "---  ------      --------------    -----         \n",
      " 0   Unnamed: 0  1600000 non-null  int64         \n",
      " 1   date        1600000 non-null  datetime64[ns]\n",
      " 2   flag        1600000 non-null  object        \n",
      " 3   text        1600000 non-null  object        \n",
      " 4   user        1600000 non-null  object        \n",
      " 5   year        1600000 non-null  int64         \n",
      " 6   month       1600000 non-null  int64         \n",
      " 7   day         1600000 non-null  int64         \n",
      " 8   hour        1600000 non-null  int64         \n",
      " 9   minute      1600000 non-null  int64         \n",
      " 10  second      1600000 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(7), object(3)\n",
      "memory usage: 134.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check if the date has been changed to date time\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec6e655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-18 15:51:40</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>@ctribe I hope you are having a great day.</td>\n",
       "      <td>prosario_2000</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-06-07 00:02:45</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Kinda scared to sleep alone in this house toni...</td>\n",
       "      <td>l7l7v</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-06-01 11:52:03</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>@karinhoegh  Didn't think of national holidays...</td>\n",
       "      <td>kmdk</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2009-06-01 11:52:03</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Need more FPS....time to shop for a new camera...</td>\n",
       "      <td>jflinchbaugh</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2009-06-01 11:52:04</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>@SteveOGallagher take me with u</td>\n",
       "      <td>kittaykat</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                date      flag  \\\n",
       "0           0 2009-04-18 15:51:40  NO_QUERY   \n",
       "1           1 2009-06-07 00:02:45  NO_QUERY   \n",
       "2           2 2009-06-01 11:52:03  NO_QUERY   \n",
       "3           3 2009-06-01 11:52:03  NO_QUERY   \n",
       "4           4 2009-06-01 11:52:04  NO_QUERY   \n",
       "\n",
       "                                                text           user  year  \\\n",
       "0        @ctribe I hope you are having a great day.   prosario_2000  2009   \n",
       "1  Kinda scared to sleep alone in this house toni...          l7l7v  2009   \n",
       "2  @karinhoegh  Didn't think of national holidays...           kmdk  2009   \n",
       "3  Need more FPS....time to shop for a new camera...   jflinchbaugh  2009   \n",
       "4                   @SteveOGallagher take me with u       kittaykat  2009   \n",
       "\n",
       "   month  day  hour  minute  second  \n",
       "0      4   18    15      51      40  \n",
       "1      6    7     0       2      45  \n",
       "2      6    1    11      52       3  \n",
       "3      6    1    11      52       3  \n",
       "4      6    1    11      52       4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the df\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f578007",
   "metadata": {},
   "source": [
    "## Drop Variables that will not be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b07fb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns except 'date' and 'text'\n",
    "df = df[['date', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f312db7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-04-18 15:51:40</td>\n",
       "      <td>@ctribe I hope you are having a great day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-06-07 00:02:45</td>\n",
       "      <td>Kinda scared to sleep alone in this house toni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-06-01 11:52:03</td>\n",
       "      <td>@karinhoegh  Didn't think of national holidays...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-01 11:52:03</td>\n",
       "      <td>Need more FPS....time to shop for a new camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-06-01 11:52:04</td>\n",
       "      <td>@SteveOGallagher take me with u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                               text\n",
       "0 2009-04-18 15:51:40        @ctribe I hope you are having a great day. \n",
       "1 2009-06-07 00:02:45  Kinda scared to sleep alone in this house toni...\n",
       "2 2009-06-01 11:52:03  @karinhoegh  Didn't think of national holidays...\n",
       "3 2009-06-01 11:52:03  Need more FPS....time to shop for a new camera...\n",
       "4 2009-06-01 11:52:04                   @SteveOGallagher take me with u "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if they have been dropped\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b2e3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by the 'date' column in ascending order\n",
    "df = df.sort_values(by='date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c88867fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2009-04-07 05:19:45</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2009-04-07 05:19:49</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2009-04-07 05:19:53</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2009-04-07 05:19:57</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2009-04-07 05:19:57</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date                                               text\n",
       "271 2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "275 2009-04-07 05:19:49  is upset that he can't update his Facebook by ...\n",
       "277 2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...\n",
       "279 2009-04-07 05:19:57    my whole body feels itchy and like its on fire \n",
       "281 2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the date is sorted\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a912a7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1600000 entries, 271 to 1546305\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype         \n",
      "---  ------  --------------    -----         \n",
      " 0   date    1600000 non-null  datetime64[ns]\n",
      " 1   text    1600000 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 36.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eeb5dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        min                 max\n",
      "month                                          \n",
      "2009-04 2009-04-07 05:19:45 2009-04-21 11:22:15\n",
      "2009-05 2009-05-02 03:08:46 2009-05-31 23:59:59\n",
      "2009-06 2009-06-01 00:00:00 2009-06-25 17:28:31\n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' column to datetime format if it's not already in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract month from 'date' column\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "\n",
    "#Group by month and find minimum and maximum date for each month\n",
    "monthly_date_range = df.groupby('month')['date'].agg([min, max])\n",
    "\n",
    "#Display the result\n",
    "print(monthly_date_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330b0fb",
   "metadata": {},
   "source": [
    "## The dates have some missing dates\n",
    "- The data is for 3 months, April, May, June\n",
    "- April (7/4/2009 - 21/4/2009)\n",
    "- May (2/5/2009) - 31/5/2009\n",
    "- June (1/6/2009 -25/6/2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c92ce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month\n",
      "2009-04    100025\n",
      "2009-05    559073\n",
      "2009-06    940902\n",
      "Freq: M, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of dates by month\n",
    "monthly_date_counts = df.groupby('month').size()\n",
    "\n",
    "# Display the result\n",
    "print(monthly_date_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2c6a099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month    day       \n",
      "2009-04  2009-04-07     20671\n",
      "         2009-04-18     17154\n",
      "         2009-04-19     32648\n",
      "         2009-04-20     18447\n",
      "         2009-04-21     11105\n",
      "2009-05  2009-05-02     31096\n",
      "         2009-05-03     26568\n",
      "         2009-05-04     28300\n",
      "         2009-05-10     31551\n",
      "         2009-05-11      6217\n",
      "         2009-05-12      4186\n",
      "         2009-05-14     21526\n",
      "         2009-05-17     41205\n",
      "         2009-05-18     44564\n",
      "         2009-05-22     41206\n",
      "         2009-05-24       169\n",
      "         2009-05-25       169\n",
      "         2009-05-27     11619\n",
      "         2009-05-29     60227\n",
      "         2009-05-30    104484\n",
      "         2009-05-31    105986\n",
      "2009-06  2009-06-01     95449\n",
      "         2009-06-02     77776\n",
      "         2009-06-03     60139\n",
      "         2009-06-04      4638\n",
      "         2009-06-05     34735\n",
      "         2009-06-06    104793\n",
      "         2009-06-07    111893\n",
      "         2009-06-08     18566\n",
      "         2009-06-14       500\n",
      "         2009-06-15     83309\n",
      "         2009-06-16     87524\n",
      "         2009-06-17     44031\n",
      "         2009-06-18     43322\n",
      "         2009-06-19     42964\n",
      "         2009-06-20     45582\n",
      "         2009-06-21     30677\n",
      "         2009-06-22      8313\n",
      "         2009-06-23     18605\n",
      "         2009-06-24      2093\n",
      "         2009-06-25     25993\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['day'] = df['date'].dt.to_period('D')\n",
    "\n",
    "# Count the number of dates by month\n",
    "dm_date_counts = df.groupby(['month', 'day']).size()\n",
    "\n",
    "# Display the result\n",
    "print(dm_date_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87750dc",
   "metadata": {},
   "source": [
    "There are missing dates in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc972211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique dates: 774363\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique dates\n",
    "unique_date_counts = df['date'].nunique()\n",
    "\n",
    "# Display the result\n",
    "print(\"Number of unique dates:\", unique_date_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52abdaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                       month         day  \n",
       "date                                      \n",
       "2009-04-07 05:19:45  2009-04  2009-04-07  \n",
       "2009-04-07 05:19:49  2009-04  2009-04-07  \n",
       "2009-04-07 05:19:53  2009-04  2009-04-07  \n",
       "2009-04-07 05:19:57  2009-04  2009-04-07  \n",
       "2009-04-07 05:19:57  2009-04  2009-04-07  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the df\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a6738",
   "metadata": {},
   "source": [
    "# EDA of the Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e31b3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of words in the text\n",
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9a83a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                     word_count  \n",
       "date                             \n",
       "2009-04-07 05:19:45          20  \n",
       "2009-04-07 05:19:49          22  \n",
       "2009-04-07 05:19:53          19  \n",
       "2009-04-07 05:19:57          11  \n",
       "2009-04-07 05:19:57          22  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"text\",\"word_count\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0e2c6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the maximum number of words in the 'word_count' variable of the 'df' DataFrame\n",
    "largest_word_count = df[\"word_count\"].max()\n",
    "largest_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be9b4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of characters in the text variable\n",
    "df['char_count'] = df['text'].str.len() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad625a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                     char_count  \n",
       "date                             \n",
       "2009-04-07 05:19:45         115  \n",
       "2009-04-07 05:19:49         111  \n",
       "2009-04-07 05:19:53          89  \n",
       "2009-04-07 05:19:57          47  \n",
       "2009-04-07 05:19:57         111  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the head of the char_count and text\n",
    "df[[\"text\",\"char_count\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cf0bbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the maximum number of characters in the 'char_count' variable of the 'df' DataFrame\n",
    "largest_char_count = df[\"char_count\"].max()\n",
    "largest_char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30a43398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to calculate the average length of words in a sentence\n",
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1921e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the avg_word function on text\n",
    "df['avg_word'] = df['text'].apply(lambda x: avg_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8af70949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>5.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>3.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>3.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                     avg_word  \n",
       "date                           \n",
       "2009-04-07 05:19:45  5.052632  \n",
       "2009-04-07 05:19:49  4.285714  \n",
       "2009-04-07 05:19:53  3.944444  \n",
       "2009-04-07 05:19:57  3.700000  \n",
       "2009-04-07 05:19:57  4.285714  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View text and avg_word\n",
    "df[['text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34790040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the highest average word count of the 'df' DataFrame\n",
    "highest_avg_word = df[\"avg_word\"].max()\n",
    "highest_avg_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c29ecb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f3292c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                     stopwords  \n",
       "date                            \n",
       "2009-04-07 05:19:45          4  \n",
       "2009-04-07 05:19:49          8  \n",
       "2009-04-07 05:19:53          5  \n",
       "2009-04-07 05:19:57          4  \n",
       "2009-04-07 05:19:57         10  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count number of stopwords in each text and store in a variable called stopwords\n",
    "df['stopwords'] = df['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "df[['text','stopwords']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13457131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the maximum number of stopwords in the 'df' DataFrame\n",
    "maximum_no_stopwords = df[\"stopwords\"].max()\n",
    "maximum_no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9e61fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                     hashtags  \n",
       "date                           \n",
       "2009-04-07 05:19:45         0  \n",
       "2009-04-07 05:19:49         0  \n",
       "2009-04-07 05:19:53         0  \n",
       "2009-04-07 05:19:57         0  \n",
       "2009-04-07 05:19:57         0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count number of hashtags in each text and store in a variable called hastags\n",
    "df['hashtags'] = df['text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "df[['text','hashtags']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e809f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the maximum number of hashtags in the 'df' DataFrame\n",
    "maximum_no_hashtags = df[\"hashtags\"].max()\n",
    "maximum_no_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ded05876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>at_sign</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                     at_sign  \n",
       "date                          \n",
       "2009-04-07 05:19:45        1  \n",
       "2009-04-07 05:19:49        0  \n",
       "2009-04-07 05:19:53        1  \n",
       "2009-04-07 05:19:57        0  \n",
       "2009-04-07 05:19:57        1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count number of @ signs in text variable and store the value in a variable called at_sign\n",
    "df['at_sign'] = df['text'].apply(lambda x: len([x for x in x.split() if x.startswith('@')]))\n",
    "df[['text','at_sign']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2797f73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the maximum number of at_sign in the 'df' DataFrame\n",
    "maximum_no_atsign = df[\"at_sign\"].max()\n",
    "maximum_no_atsign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "147097f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                     numerics  \n",
       "date                           \n",
       "2009-04-07 05:19:45         0  \n",
       "2009-04-07 05:19:49         0  \n",
       "2009-04-07 05:19:53         0  \n",
       "2009-04-07 05:19:57         0  \n",
       "2009-04-07 05:19:57         0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count number of numerics in the text variable and store the value in a variable called numeric\n",
    "df['numerics'] = df['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "df[['text','numerics']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "323bf746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the maximum number of numerics in the 'df' DataFrame\n",
    "maximum_no_numerics = df[\"numerics\"].max()\n",
    "maximum_no_numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3766413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  upper\n",
       "date                                                                         \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...      1\n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...      0\n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...      1\n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire       0\n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count number of uppercases in the text variable and store the value in a variable called upper\n",
    "df['upper'] = df['text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "df[['text','upper']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "626bd48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the maximum number of uppercases in the 'df' DataFrame\n",
    "maximum_no_uppercases = df[\"upper\"].max()\n",
    "maximum_no_uppercases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3540853d",
   "metadata": {},
   "source": [
    "## Tweets Processing\n",
    "Tweet/text processing involves:-\n",
    "\n",
    "a) Text Normalization \n",
    "- Remove special characters\n",
    "- Change the upper cases to lower cases\n",
    "- Remove numbers/integers\n",
    "- Remove punctuations\n",
    "- Remove white space\n",
    "- Remove URLS/links\n",
    "\n",
    "b) Tokenization\n",
    "- Tokenization\n",
    "\n",
    "c) Remove stopwords\n",
    "\n",
    "d) Stemming/ lemmatization\n",
    "\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19841ca9",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e4e26e",
   "metadata": {},
   "source": [
    "### Remove user name from text @username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b90d3119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2009-04-07 05:19:45     http://twitpic.com/2y1zl - Awww, that's a bum...\n",
      "2009-04-07 05:19:49    is upset that he can't update his Facebook by ...\n",
      "2009-04-07 05:19:53     I dived many times for the ball. Managed to s...\n",
      "2009-04-07 05:19:57      my whole body feels itchy and like its on fire \n",
      "2009-04-07 05:19:57     no, it's not behaving at all. i'm mad. why am...\n",
      "Name: text1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#Define a function to remove user names from text\n",
    "def remove_usernames(text):\n",
    "    return re.sub(r'@\\w+', '', text)\n",
    "\n",
    "#Apply the function to the 'text' variable\n",
    "df['text1'] = df['text'].apply(remove_usernames)\n",
    "\n",
    "# Print the first few rows of the DataFrame with user names removed from text\n",
    "print(df['text1'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a8c22e",
   "metadata": {},
   "source": [
    "### Remove url/www.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "710a235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_urls(df):\n",
    "    #Define regex pattern to match URLs\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    \n",
    "    #Apply regex substitution to each row of the 'text' column\n",
    "    df['text1'] = df['text1'].apply(lambda text: re.sub(url_pattern, '', text))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# remove a url\n",
    "df = remove_urls(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "499c6017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>at_sign</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>text1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>20</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>22</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I dived many times for the ball. Managed to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>22</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                       month         day  word_count  char_count  avg_word  \\\n",
       "date                                                                         \n",
       "2009-04-07 05:19:45  2009-04  2009-04-07          20         115  5.052632   \n",
       "2009-04-07 05:19:49  2009-04  2009-04-07          22         111  4.285714   \n",
       "2009-04-07 05:19:53  2009-04  2009-04-07          19          89  3.944444   \n",
       "2009-04-07 05:19:57  2009-04  2009-04-07          11          47  3.700000   \n",
       "2009-04-07 05:19:57  2009-04  2009-04-07          22         111  4.285714   \n",
       "\n",
       "                     stopwords  hashtags  at_sign  numerics  upper  \\\n",
       "date                                                                 \n",
       "2009-04-07 05:19:45          4         0        1         0      1   \n",
       "2009-04-07 05:19:49          8         0        0         0      0   \n",
       "2009-04-07 05:19:53          5         0        1         0      1   \n",
       "2009-04-07 05:19:57          4         0        0         0      0   \n",
       "2009-04-07 05:19:57         10         0        1         0      1   \n",
       "\n",
       "                                                                 text1  \n",
       "date                                                                    \n",
       "2009-04-07 05:19:45    - Awww, that's a bummer.  You shoulda got Da...  \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...  \n",
       "2009-04-07 05:19:53   I dived many times for the ball. Managed to s...  \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire   \n",
       "2009-04-07 05:19:57   no, it's not behaving at all. i'm mad. why am...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6dfdb",
   "metadata": {},
   "source": [
    "### Remove all special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dac14dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diana\\AppData\\Local\\Temp\\ipykernel_16768\\1096157190.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text1'] = df['text1'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "2009-04-07 05:19:45       Awww thats a bummer  You shoulda got David ...\n",
       "2009-04-07 05:19:49    is upset that he cant update his Facebook by t...\n",
       "2009-04-07 05:19:53     I dived many times for the ball Managed to sa...\n",
       "2009-04-07 05:19:57      my whole body feels itchy and like its on fire \n",
       "2009-04-07 05:19:57     no its not behaving at all im mad why am i he...\n",
       "Name: text1, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove all special characters\n",
    "df['text1'] = df['text1'].str.replace('[^\\w\\s]','')\n",
    "df['text1'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d4d6a",
   "metadata": {},
   "source": [
    "### Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1880099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuations\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "#Apply remove_punctuation function to the 'text' column\n",
    "df['text1'] = df['text1'].apply(remove_punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "001622d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>at_sign</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>text1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>20</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Awww thats a bummer  You shoulda got David ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>22</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he cant update his Facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I dived many times for the ball Managed to sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>22</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no its not behaving at all im mad why am i he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                       month         day  word_count  char_count  avg_word  \\\n",
       "date                                                                         \n",
       "2009-04-07 05:19:45  2009-04  2009-04-07          20         115  5.052632   \n",
       "2009-04-07 05:19:49  2009-04  2009-04-07          22         111  4.285714   \n",
       "2009-04-07 05:19:53  2009-04  2009-04-07          19          89  3.944444   \n",
       "2009-04-07 05:19:57  2009-04  2009-04-07          11          47  3.700000   \n",
       "2009-04-07 05:19:57  2009-04  2009-04-07          22         111  4.285714   \n",
       "\n",
       "                     stopwords  hashtags  at_sign  numerics  upper  \\\n",
       "date                                                                 \n",
       "2009-04-07 05:19:45          4         0        1         0      1   \n",
       "2009-04-07 05:19:49          8         0        0         0      0   \n",
       "2009-04-07 05:19:53          5         0        1         0      1   \n",
       "2009-04-07 05:19:57          4         0        0         0      0   \n",
       "2009-04-07 05:19:57         10         0        1         0      1   \n",
       "\n",
       "                                                                 text1  \n",
       "date                                                                    \n",
       "2009-04-07 05:19:45     Awww thats a bummer  You shoulda got David ...  \n",
       "2009-04-07 05:19:49  is upset that he cant update his Facebook by t...  \n",
       "2009-04-07 05:19:53   I dived many times for the ball Managed to sa...  \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire   \n",
       "2009-04-07 05:19:57   no its not behaving at all im mad why am i he...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b092d",
   "metadata": {},
   "source": [
    "### Convert all upper cases to lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "964c9401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2009-04-07 05:19:45    awww thats a bummer you shoulda got david carr...\n",
       "2009-04-07 05:19:49    is upset that he cant update his facebook by t...\n",
       "2009-04-07 05:19:53    i dived many times for the ball managed to sav...\n",
       "2009-04-07 05:19:57       my whole body feels itchy and like its on fire\n",
       "2009-04-07 05:19:57    no its not behaving at all im mad why am i her...\n",
       "Name: text1, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert all uppercases to lower cases\n",
    "df['text1'] = df['text1'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['text1'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7471e7",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0d7abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Diana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Diana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Diana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Diana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5aa21",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7b209b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>awww thats a bummer you shoulda got david carr...</td>\n",
       "      <td>awww thats a bummer you shoulda got david carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>no its not behaving at all im mad why am i her...</td>\n",
       "      <td>no its not behaving at all im mad why am i her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text1  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  awww thats a bummer you shoulda got david carr...   \n",
       "2009-04-07 05:19:49  is upset that he cant update his facebook by t...   \n",
       "2009-04-07 05:19:53  i dived many times for the ball managed to sav...   \n",
       "2009-04-07 05:19:57     my whole body feels itchy and like its on fire   \n",
       "2009-04-07 05:19:57  no its not behaving at all im mad why am i her...   \n",
       "\n",
       "                                                        tokenized_text  \n",
       "date                                                                    \n",
       "2009-04-07 05:19:45  awww thats a bummer you shoulda got david carr...  \n",
       "2009-04-07 05:19:49  is upset that he cant update his facebook by t...  \n",
       "2009-04-07 05:19:53  i dived many times for the ball managed to sav...  \n",
       "2009-04-07 05:19:57     my whole body feels itchy and like its on fire  \n",
       "2009-04-07 05:19:57  no its not behaving at all im mad why am i her...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Tokenize the text using NLTK's word tokenizer\n",
    "df['tokenized_text'] = df['text1'].apply(lambda x: ' '.join(word_tokenize(x.lower())))\n",
    "\n",
    "#Print the first few rows of the DataFrame with tokenized text\n",
    "df[['text1', 'tokenized_text']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a2c8b",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "559282bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Diana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 text1  \\\n",
      "date                                                                     \n",
      "2009-04-07 05:19:45  awww thats a bummer you shoulda got david carr...   \n",
      "2009-04-07 05:19:49  is upset that he cant update his facebook by t...   \n",
      "2009-04-07 05:19:53  i dived many times for the ball managed to sav...   \n",
      "2009-04-07 05:19:57     my whole body feels itchy and like its on fire   \n",
      "2009-04-07 05:19:57  no its not behaving at all im mad why am i her...   \n",
      "\n",
      "                                                        tokenized_text  \n",
      "date                                                                    \n",
      "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...  \n",
      "2009-04-07 05:19:49  upset cant update facebook texting might cry r...  \n",
      "2009-04-07 05:19:53  dived many times ball managed save 50 rest go ...  \n",
      "2009-04-07 05:19:57                   whole body feels itchy like fire  \n",
      "2009-04-07 05:19:57                           behaving im mad cant see  \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Download NLTK resources for the first time\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#Get the English stopwords list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#Function to remove stopwords\n",
    "def remove_stopwords(tokenized_text):\n",
    "    return ' '.join([word for word in tokenized_text.split() if word.lower() not in stop_words])\n",
    "\n",
    "#Remove stopwords from the tokenized text column\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(remove_stopwords)\n",
    "\n",
    "# Print the first few rows of the DataFrame with stopwords removed\n",
    "print(df[['text1', 'tokenized_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a644e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Frequency Distribution of the tokenized words\n",
    "#Import Frequency Distribution\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#Find frequency distribution of tokenized_text\n",
    "fdist = FreqDist(df['tokenized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63a6160e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 6847),\n",
       " ('thanks', 2329),\n",
       " ('thank', 1573),\n",
       " ('get 100 followers day using add everyone train pay vip', 1484),\n",
       " ('good morning', 1134)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check top 5 common words\n",
    "fdist.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d491a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a frequency distribution plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot Frequency Distribution\n",
    "fdist.plot(20,cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7228717a",
   "metadata": {},
   "source": [
    "## Stemming/ lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9eed33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        tokenized_text  \\\n",
      "date                                                                     \n",
      "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
      "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
      "2009-04-07 05:19:53  dived many times ball managed save 50 rest go ...   \n",
      "2009-04-07 05:19:57                   whole body feels itchy like fire   \n",
      "2009-04-07 05:19:57                           behaving im mad cant see   \n",
      "\n",
      "                                                     preprocessed_text  \n",
      "date                                                                    \n",
      "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...  \n",
      "2009-04-07 05:19:49  upset cant update facebook texting might cry r...  \n",
      "2009-04-07 05:19:53  dived many time ball managed save 50 rest go b...  \n",
      "2009-04-07 05:19:57                    whole body feel itchy like fire  \n",
      "2009-04-07 05:19:57                           behaving im mad cant see  \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize text\n",
    "def lemmatize_text(tokenized_text):\n",
    "    #Lemmatize the tokens\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokenized_text.split()]\n",
    "    \n",
    "    #Join the lemmatized tokens back into a string\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    return lemmatized_text\n",
    "\n",
    "#Apply lemmatization to 'tokenized_text' column in DataFrame df\n",
    "df['preprocessed_text'] = df['tokenized_text'].apply(lemmatize_text)\n",
    "\n",
    "#Print the first few rows of the DataFrame with lemmatized text\n",
    "print(df[['tokenized_text', 'preprocessed_text']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb30a3",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS\n",
    "There are various ways to perform sentiment analysis. These include:-\n",
    "- Using Text Blob\n",
    "- Using Vader\n",
    "- Using Bag of Words Vectorization-based Models\n",
    "- Using LSTM-based Models\n",
    "- Using Transformer-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa0312",
   "metadata": {},
   "source": [
    "## USING TEXTBLOB\n",
    "-  It takes text as an input and can return polarity and subjectivity as outputs.\n",
    "\n",
    "- Polarity determines the sentiment of the text. Its values lie in [-1,1] where -1 denotes a highly negative sentiment and 1 denotes a highly positive sentiment.\n",
    "\n",
    "- Subjectivity determines whether a text input is factual information or a personal opinion. Its value lies between [0,1] where a value closer to 0 denotes a piece of factual information and a value closer to 1 denotes a personal opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84db8020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>dived many time ball managed save 50 rest go b...</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>behaving im mad cant see</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     preprocessed_text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
       "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
       "2009-04-07 05:19:53  dived many time ball managed save 50 rest go b...   \n",
       "2009-04-07 05:19:57                    whole body feel itchy like fire   \n",
       "2009-04-07 05:19:57                           behaving im mad cant see   \n",
       "\n",
       "                     polarity_score  \n",
       "date                                 \n",
       "2009-04-07 05:19:45           0.200  \n",
       "2009-04-07 05:19:49           0.000  \n",
       "2009-04-07 05:19:53           0.500  \n",
       "2009-04-07 05:19:57           0.200  \n",
       "2009-04-07 05:19:57          -0.625  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "#Apply sentiment analysis using TextBlob to the 'text' column and storing the polarity score\n",
    "df['polarity_score'] = df['preprocessed_text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "df[['preprocessed_text','polarity_score']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b357cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>at_sign</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>text1</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>20</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>awww thats a bummer you shoulda got david carr...</td>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>22</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>dived many times ball managed save 50 rest go ...</td>\n",
       "      <td>dived many time ball managed save 50 rest go b...</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>22</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no its not behaving at all im mad why am i her...</td>\n",
       "      <td>behaving im mad cant see</td>\n",
       "      <td>behaving im mad cant see</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                       month         day  word_count  char_count  avg_word  \\\n",
       "date                                                                         \n",
       "2009-04-07 05:19:45  2009-04  2009-04-07          20         115  5.052632   \n",
       "2009-04-07 05:19:49  2009-04  2009-04-07          22         111  4.285714   \n",
       "2009-04-07 05:19:53  2009-04  2009-04-07          19          89  3.944444   \n",
       "2009-04-07 05:19:57  2009-04  2009-04-07          11          47  3.700000   \n",
       "2009-04-07 05:19:57  2009-04  2009-04-07          22         111  4.285714   \n",
       "\n",
       "                     stopwords  hashtags  at_sign  numerics  upper  \\\n",
       "date                                                                 \n",
       "2009-04-07 05:19:45          4         0        1         0      1   \n",
       "2009-04-07 05:19:49          8         0        0         0      0   \n",
       "2009-04-07 05:19:53          5         0        1         0      1   \n",
       "2009-04-07 05:19:57          4         0        0         0      0   \n",
       "2009-04-07 05:19:57         10         0        1         0      1   \n",
       "\n",
       "                                                                 text1  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  awww thats a bummer you shoulda got david carr...   \n",
       "2009-04-07 05:19:49  is upset that he cant update his facebook by t...   \n",
       "2009-04-07 05:19:53  i dived many times for the ball managed to sav...   \n",
       "2009-04-07 05:19:57     my whole body feels itchy and like its on fire   \n",
       "2009-04-07 05:19:57  no its not behaving at all im mad why am i her...   \n",
       "\n",
       "                                                        tokenized_text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
       "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
       "2009-04-07 05:19:53  dived many times ball managed save 50 rest go ...   \n",
       "2009-04-07 05:19:57                   whole body feels itchy like fire   \n",
       "2009-04-07 05:19:57                           behaving im mad cant see   \n",
       "\n",
       "                                                     preprocessed_text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
       "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
       "2009-04-07 05:19:53  dived many time ball managed save 50 rest go b...   \n",
       "2009-04-07 05:19:57                    whole body feel itchy like fire   \n",
       "2009-04-07 05:19:57                           behaving im mad cant see   \n",
       "\n",
       "                     polarity_score  \n",
       "date                                 \n",
       "2009-04-07 05:19:45           0.200  \n",
       "2009-04-07 05:19:49           0.000  \n",
       "2009-04-07 05:19:53           0.500  \n",
       "2009-04-07 05:19:57           0.200  \n",
       "2009-04-07 05:19:57          -0.625  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the df, first 5 observations\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "addca82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1600000 entries, 2009-04-07 05:19:45 to 2009-06-25 17:28:31\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count    Dtype    \n",
      "---  ------             --------------    -----    \n",
      " 0   text               1600000 non-null  object   \n",
      " 1   month              1600000 non-null  period[M]\n",
      " 2   day                1600000 non-null  period[D]\n",
      " 3   word_count         1600000 non-null  int64    \n",
      " 4   char_count         1600000 non-null  int64    \n",
      " 5   avg_word           1600000 non-null  float64  \n",
      " 6   stopwords          1600000 non-null  int64    \n",
      " 7   hashtags           1600000 non-null  int64    \n",
      " 8   at_sign            1600000 non-null  int64    \n",
      " 9   numerics           1600000 non-null  int64    \n",
      " 10  upper              1600000 non-null  int64    \n",
      " 11  text1              1600000 non-null  object   \n",
      " 12  tokenized_text     1600000 non-null  object   \n",
      " 13  preprocessed_text  1600000 non-null  object   \n",
      " 14  polarity_score     1600000 non-null  float64  \n",
      "dtypes: float64(2), int64(7), object(4), period[D](1), period[M](1)\n",
      "memory usage: 227.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#View data types of the variables\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0953792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     preprocessed_text  \\\n",
      "date                                                                     \n",
      "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
      "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
      "2009-04-07 05:19:53  dived many time ball managed save 50 rest go b...   \n",
      "2009-04-07 05:19:57                    whole body feel itchy like fire   \n",
      "2009-04-07 05:19:57                           behaving im mad cant see   \n",
      "\n",
      "                     polarity_score textblob_sentiment  \n",
      "date                                                    \n",
      "2009-04-07 05:19:45           0.200           Positive  \n",
      "2009-04-07 05:19:49           0.000            Neutral  \n",
      "2009-04-07 05:19:53           0.500           Positive  \n",
      "2009-04-07 05:19:57           0.200           Positive  \n",
      "2009-04-07 05:19:57          -0.625           Negative  \n"
     ]
    }
   ],
   "source": [
    "# Function to categorize sentiment polarities\n",
    "def categorize_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply the function to classify polarity scores and store the result in 'textblob_sentiment' column\n",
    "df['textblob_sentiment'] = df['polarity_score'].apply(categorize_sentiment)\n",
    "\n",
    "# Print the first few rows of the DataFrame with 'textblob_sentiment' column\n",
    "print(df[['preprocessed_text', 'polarity_score', 'textblob_sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a8b016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>textblobsentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "      <td>0.200</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>dived many time ball managed save 50 rest go b...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>0.200</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>behaving im mad cant see</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     preprocessed_text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
       "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
       "2009-04-07 05:19:53  dived many time ball managed save 50 rest go b...   \n",
       "2009-04-07 05:19:57                    whole body feel itchy like fire   \n",
       "2009-04-07 05:19:57                           behaving im mad cant see   \n",
       "\n",
       "                     polarity_score textblob_sentiment  textblobsentiment  \n",
       "date                                                                       \n",
       "2009-04-07 05:19:45           0.200           Positive                  1  \n",
       "2009-04-07 05:19:49           0.000            Neutral                  0  \n",
       "2009-04-07 05:19:53           0.500           Positive                  1  \n",
       "2009-04-07 05:19:57           0.200           Positive                  1  \n",
       "2009-04-07 05:19:57          -0.625           Negative                 -1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to categorize sentiment polarities\n",
    "# Categorize sentiment polarities\n",
    "def categorize_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return 1  # Positive\n",
    "    elif polarity < 0:\n",
    "        return -1  # Negative\n",
    "    else:\n",
    "        return 0  # Neutral\n",
    "\n",
    "# Apply the function to classify polarity scores and store the result in 'textblob_sentiment' column\n",
    "df['textblobsentiment'] = df['polarity_score'].apply(categorize_sentiment)\n",
    "\n",
    "#View the first few rows of the DataFrame with 'textblob_sentiment' column\n",
    "df[['preprocessed_text', 'polarity_score', 'textblob_sentiment','textblobsentiment']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2cc4b4",
   "metadata": {},
   "source": [
    "# USING VADER SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b412ffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Diana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b59864cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     preprocessed_text  \\\n",
      "date                                                                     \n",
      "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
      "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
      "2009-04-07 05:19:53  dived many time ball managed save 50 rest go b...   \n",
      "2009-04-07 05:19:57                    whole body feel itchy like fire   \n",
      "2009-04-07 05:19:57                           behaving im mad cant see   \n",
      "...                                                                ...   \n",
      "2009-06-25 17:28:28             sick spending day laying bed listening   \n",
      "2009-06-25 17:28:28                                              gmail   \n",
      "2009-06-25 17:28:30                              rest peace farrah sad   \n",
      "2009-06-25 17:28:30           sound like rival flagging ad much though   \n",
      "2009-06-25 17:28:31  resit exam summer wish worked harder first yea...   \n",
      "\n",
      "                     vader_compound sentiment_vader  \n",
      "date                                                 \n",
      "2009-04-07 05:19:45         -0.3818        negative  \n",
      "2009-04-07 05:19:49         -0.7269        negative  \n",
      "2009-04-07 05:19:53          0.4939        positive  \n",
      "2009-04-07 05:19:57         -0.2500        negative  \n",
      "2009-04-07 05:19:57         -0.4939        negative  \n",
      "...                             ...             ...  \n",
      "2009-06-25 17:28:28         -0.5106        negative  \n",
      "2009-06-25 17:28:28          0.0000         neutral  \n",
      "2009-06-25 17:28:30          0.1027        positive  \n",
      "2009-06-25 17:28:30          0.3612        positive  \n",
      "2009-06-25 17:28:31          0.4019        positive  \n",
      "\n",
      "[1600000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create a VADER SentimentIntensityAnalyzer instance\n",
    "twitter_sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Create a function to get compound sentiment score using VADER\n",
    "def get_sentiment_scores(text):\n",
    "    return twitter_sentiment.polarity_scores(text)\n",
    "\n",
    "#Apply the function to get the compound scores and store the values in vader_sentiment\n",
    "df['vader_sentiment'] = df['preprocessed_text'].apply(get_sentiment_scores)\n",
    "\n",
    "#Extract the 'neg', 'neu', 'pos', 'compound' scores from 'vader_sentiment'\n",
    "df['vader_neg'] = df['vader_sentiment'].apply(lambda x: x['neg'])\n",
    "df['vader_neu'] = df['vader_sentiment'].apply(lambda x: x['neu'])\n",
    "df['vader_pos'] = df['vader_sentiment'].apply(lambda x: x['pos'])\n",
    "df['vader_compound'] = df['vader_sentiment'].apply(lambda x: x['compound'])\n",
    "\n",
    "#Create a function to categorize sentiments based on compound scores\n",
    "def categorize_sentiment(vader_compound):\n",
    "    if vader_compound >= 0.05:\n",
    "        return 'positive'\n",
    "    elif vader_compound <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "#Apply the categorization function to create the 'sentiment' column\n",
    "df['sentiment_vader'] = df['vader_compound'].apply(categorize_sentiment)\n",
    "\n",
    "#Display the updated DataFrame with the 'sentiment' column\n",
    "print(df[['preprocessed_text','vader_compound','sentiment_vader']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27c258aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>at_sign</th>\n",
       "      <th>numerics</th>\n",
       "      <th>...</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>textblobsentiment</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>sentiment_vader</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>20</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "      <td>0.200</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.245, 'neu': 0.755, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>22</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.441, 'neu': 0.559, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7269</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>dived many time ball managed save 50 rest go b...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.738, 'pos': 0.262, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>0.200</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.45, 'neu': 0.3, 'pos': 0.25, 'compou...</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>22</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>behaving im mad cant see</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'neg': 0.444, 'neu': 0.556, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-07 05:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-07 05:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-07 05:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-07 05:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                       month         day  word_count  char_count  avg_word  \\\n",
       "date                                                                         \n",
       "2009-04-07 05:19:45  2009-04  2009-04-07          20         115  5.052632   \n",
       "2009-04-07 05:19:49  2009-04  2009-04-07          22         111  4.285714   \n",
       "2009-04-07 05:19:53  2009-04  2009-04-07          19          89  3.944444   \n",
       "2009-04-07 05:19:57  2009-04  2009-04-07          11          47  3.700000   \n",
       "2009-04-07 05:19:57  2009-04  2009-04-07          22         111  4.285714   \n",
       "\n",
       "                     stopwords  hashtags  at_sign  numerics  ...  \\\n",
       "date                                                         ...   \n",
       "2009-04-07 05:19:45          4         0        1         0  ...   \n",
       "2009-04-07 05:19:49          8         0        0         0  ...   \n",
       "2009-04-07 05:19:53          5         0        1         0  ...   \n",
       "2009-04-07 05:19:57          4         0        0         0  ...   \n",
       "2009-04-07 05:19:57         10         0        1         0  ...   \n",
       "\n",
       "                                                     preprocessed_text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
       "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
       "2009-04-07 05:19:53  dived many time ball managed save 50 rest go b...   \n",
       "2009-04-07 05:19:57                    whole body feel itchy like fire   \n",
       "2009-04-07 05:19:57                           behaving im mad cant see   \n",
       "\n",
       "                    polarity_score textblob_sentiment textblobsentiment  \\\n",
       "date                                                                      \n",
       "2009-04-07 05:19:45          0.200           Positive                 1   \n",
       "2009-04-07 05:19:49          0.000            Neutral                 0   \n",
       "2009-04-07 05:19:53          0.500           Positive                 1   \n",
       "2009-04-07 05:19:57          0.200           Positive                 1   \n",
       "2009-04-07 05:19:57         -0.625           Negative                -1   \n",
       "\n",
       "                                                       vader_sentiment  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  {'neg': 0.245, 'neu': 0.755, 'pos': 0.0, 'comp...   \n",
       "2009-04-07 05:19:49  {'neg': 0.441, 'neu': 0.559, 'pos': 0.0, 'comp...   \n",
       "2009-04-07 05:19:53  {'neg': 0.0, 'neu': 0.738, 'pos': 0.262, 'comp...   \n",
       "2009-04-07 05:19:57  {'neg': 0.45, 'neu': 0.3, 'pos': 0.25, 'compou...   \n",
       "2009-04-07 05:19:57  {'neg': 0.444, 'neu': 0.556, 'pos': 0.0, 'comp...   \n",
       "\n",
       "                    vader_neg  vader_neu vader_pos  vader_compound  \\\n",
       "date                                                                 \n",
       "2009-04-07 05:19:45     0.245      0.755     0.000         -0.3818   \n",
       "2009-04-07 05:19:49     0.441      0.559     0.000         -0.7269   \n",
       "2009-04-07 05:19:53     0.000      0.738     0.262          0.4939   \n",
       "2009-04-07 05:19:57     0.450      0.300     0.250         -0.2500   \n",
       "2009-04-07 05:19:57     0.444      0.556     0.000         -0.4939   \n",
       "\n",
       "                     sentiment_vader  \n",
       "date                                  \n",
       "2009-04-07 05:19:45         negative  \n",
       "2009-04-07 05:19:49         negative  \n",
       "2009-04-07 05:19:53         positive  \n",
       "2009-04-07 05:19:57         negative  \n",
       "2009-04-07 05:19:57         negative  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the first 5 observations\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ead0c",
   "metadata": {},
   "source": [
    "# Determine which one to use between vader and textblob by evaluating their performance using "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c07492",
   "metadata": {},
   "source": [
    "# Using TfidfVectorizer, countvectorizer AND MNB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a14a0e",
   "metadata": {},
   "source": [
    "## Textblob sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d9d1840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.61      0.74     65507\n",
      "     Neutral       0.80      0.80      0.80    118524\n",
      "    Positive       0.77      0.90      0.83    135969\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.83      0.77      0.79    320000\n",
      "weighted avg       0.81      0.80      0.80    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Vectorize the Text Data using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    "                        stop_words='english', ngram_range=(1,1))\n",
    "X = tfidf.fit_transform(df['text'])\n",
    "y = df['textblob_sentiment']\n",
    "\n",
    "#Split the data into Train-Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Create a classifier for MNB\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "#Train the Classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the Model\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83241110",
   "metadata": {},
   "source": [
    "## vader sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2dcd4167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.56      0.68     77743\n",
      "     neutral       0.73      0.56      0.64     89026\n",
      "    positive       0.69      0.91      0.79    153231\n",
      "\n",
      "    accuracy                           0.73    320000\n",
      "   macro avg       0.76      0.68      0.70    320000\n",
      "weighted avg       0.74      0.73      0.72    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Vectorize the Text Data using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    "                        stop_words='english', ngram_range=(1,1))\n",
    "X = tfidf.fit_transform(df['text'])\n",
    "y = df['sentiment_vader']\n",
    "\n",
    "#Split the data into Train-Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Create a classifier for MNB\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "#Train the Classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the Model\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06692d6a",
   "metadata": {},
   "source": [
    "## USING COUNTVECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ef3ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diana\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1600000x656186 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11959098 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre-Processing using Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv    = CountVectorizer(stop_words = 'english',ngram_range = (1, 1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(df['text'])\n",
    "\n",
    "text_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915952d",
   "metadata": {},
   "source": [
    "## textblob sentiments using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd928b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracuy Score:  0.833203125\n"
     ]
    }
   ],
   "source": [
    "#Split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, df['textblob_sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "#Training the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "\n",
    "#Caluclate the accuracy score of the model\n",
    "from sklearn import metrics\n",
    "predicted = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
    "print(\"Accuracuy Score: \",accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793e625",
   "metadata": {},
   "source": [
    "## vader sentiments using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6504f585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracuy Score:  0.76886\n"
     ]
    }
   ],
   "source": [
    "#Split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, df['sentiment_vader'], test_size=0.25, random_state=5)\n",
    "\n",
    "#Training the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "\n",
    "#Caluclate the accuracy score of the model\n",
    "from sklearn import metrics\n",
    "predicted = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
    "print(\"Accuracuy Score: \",accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "79053494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1600000 entries, 2009-04-07 05:19:45 to 2009-06-25 17:28:31\n",
      "Data columns (total 24 columns):\n",
      " #   Column              Non-Null Count    Dtype    \n",
      "---  ------              --------------    -----    \n",
      " 0   text                1600000 non-null  object   \n",
      " 1   month               1600000 non-null  period[M]\n",
      " 2   day                 1600000 non-null  period[D]\n",
      " 3   word_count          1600000 non-null  int64    \n",
      " 4   char_count          1600000 non-null  int64    \n",
      " 5   avg_word            1600000 non-null  float64  \n",
      " 6   stopwords           1600000 non-null  int64    \n",
      " 7   hashtags            1600000 non-null  int64    \n",
      " 8   at_sign             1600000 non-null  int64    \n",
      " 9   numerics            1600000 non-null  int64    \n",
      " 10  upper               1600000 non-null  int64    \n",
      " 11  text1               1600000 non-null  object   \n",
      " 12  tokenized_text      1600000 non-null  object   \n",
      " 13  preprocessed_text   1600000 non-null  object   \n",
      " 14  polarity_score      1600000 non-null  float64  \n",
      " 15  textblob_sentiment  1600000 non-null  object   \n",
      " 16  textblobsentiment   1600000 non-null  int64    \n",
      " 17  vader_sentiment     1600000 non-null  object   \n",
      " 18  vader_neg           1600000 non-null  float64  \n",
      " 19  vader_neu           1600000 non-null  float64  \n",
      " 20  vader_pos           1600000 non-null  float64  \n",
      " 21  vader_compound      1600000 non-null  float64  \n",
      " 22  sentiment_vader     1600000 non-null  object   \n",
      " 23  sentiment_encoded   1600000 non-null  int32    \n",
      "dtypes: float64(6), int32(1), int64(8), object(7), period[D](1), period[M](1)\n",
      "memory usage: 331.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check the variables data type\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47448b",
   "metadata": {},
   "source": [
    "Since the accuracy of sentiments extracted by textblob is higher sentiments extracted by textblob will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08d1cb",
   "metadata": {},
   "source": [
    "## Encode the Sentiments\n",
    "Try \n",
    "label and one hot and see which one performs better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a5205",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "47942a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diana\\AppData\\Local\\Temp\\ipykernel_16768\\1733639092.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['sentiment_encoded'] = label_encoder.fit_transform(df2['textblob_sentiment'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'sentiment' column\n",
    "df2['label_encoded'] = label_encoder.fit_transform(df2['textblob_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643ef01",
   "metadata": {},
   "source": [
    "## One-hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b83cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9ae35f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>sentiment_encoded</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>dived many time ball managed save 50 rest go b...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>behaving im mad cant see</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     preprocessed_text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
       "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
       "2009-04-07 05:19:53  dived many time ball managed save 50 rest go b...   \n",
       "2009-04-07 05:19:57                    whole body feel itchy like fire   \n",
       "2009-04-07 05:19:57                           behaving im mad cant see   \n",
       "\n",
       "                     sentiment_encoded textblob_sentiment  \n",
       "date                                                       \n",
       "2009-04-07 05:19:45                  2           Positive  \n",
       "2009-04-07 05:19:49                  1            Neutral  \n",
       "2009-04-07 05:19:53                  2           Positive  \n",
       "2009-04-07 05:19:57                  2           Positive  \n",
       "2009-04-07 05:19:57                  0           Negative  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all columns that are unused\n",
    "df2 = df[['preprocessed_text','sentiment_encoded','textblob_sentiment']]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4d484baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>sentiment_encoded</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>dived many time ball managed save 50 rest go b...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>behaving im mad cant see</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     preprocessed_text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
       "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
       "2009-04-07 05:19:53  dived many time ball managed save 50 rest go b...   \n",
       "2009-04-07 05:19:57                    whole body feel itchy like fire   \n",
       "2009-04-07 05:19:57                           behaving im mad cant see   \n",
       "\n",
       "                     sentiment_encoded textblob_sentiment  \n",
       "date                                                       \n",
       "2009-04-07 05:19:45                  2           Positive  \n",
       "2009-04-07 05:19:49                  1            Neutral  \n",
       "2009-04-07 05:19:53                  2           Positive  \n",
       "2009-04-07 05:19:57                  2           Positive  \n",
       "2009-04-07 05:19:57                  0           Negative  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vie the data info\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "79c24b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1600000 entries, 2009-04-07 05:19:45 to 2009-06-25 17:28:31\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count    Dtype \n",
      "---  ------              --------------    ----- \n",
      " 0   preprocessed_text   1600000 non-null  object\n",
      " 1   sentiment_encoded   1600000 non-null  int32 \n",
      " 2   textblob_sentiment  1600000 non-null  object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 75.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check the df2 info\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a0032682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>sentiment_encoded</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:45</th>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:49</th>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:53</th>\n",
       "      <td>dived many time ball managed save 50 rest go b...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-07 05:19:57</th>\n",
       "      <td>behaving im mad cant see</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     preprocessed_text  \\\n",
       "date                                                                     \n",
       "2009-04-07 05:19:45  awww thats bummer shoulda got david carr third...   \n",
       "2009-04-07 05:19:49  upset cant update facebook texting might cry r...   \n",
       "2009-04-07 05:19:53  dived many time ball managed save 50 rest go b...   \n",
       "2009-04-07 05:19:57                    whole body feel itchy like fire   \n",
       "2009-04-07 05:19:57                           behaving im mad cant see   \n",
       "\n",
       "                     sentiment_encoded textblob_sentiment  \n",
       "date                                                       \n",
       "2009-04-07 05:19:45                  2           Positive  \n",
       "2009-04-07 05:19:49                  1            Neutral  \n",
       "2009-04-07 05:19:53                  2           Positive  \n",
       "2009-04-07 05:19:57                  2           Positive  \n",
       "2009-04-07 05:19:57                  0           Negative  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1c295105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.600000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.220185e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.618375e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment_encoded\n",
       "count       1.600000e+06\n",
       "mean        1.220185e+00\n",
       "std         7.618375e-01\n",
       "min         0.000000e+00\n",
       "25%         1.000000e+00\n",
       "50%         1.000000e+00\n",
       "75%         2.000000e+00\n",
       "max         2.000000e+00"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c795101b",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5a2966a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Counts:\n",
      "Positive    679250\n",
      "Neutral     593796\n",
      "Negative    326954\n",
      "Name: textblob_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Count occurrences of each sentiment class\n",
    "sentiment_counts = df2['textblob_sentiment'].value_counts()\n",
    "\n",
    "# Display the result as a table\n",
    "print(\"Sentiment Counts:\")\n",
    "print(sentiment_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d1176",
   "metadata": {},
   "source": [
    "There is class imbalance, in the sentiment data. Class imbalance occurs when one class (or classes) has significantly more samples than the other classes. In this case, the counts of sentiment classes are as follows:\n",
    "\n",
    "\n",
    "Class 2: 679,250 samples\n",
    "\n",
    "Class 0: 593,796 samples\n",
    "\n",
    "Class 1: 326,954 samples\n",
    "    \n",
    "The class imbalance can potentially affect the performance of the machine learning model, especially if the minority class (in this case, class 1) \n",
    "\n",
    "To address class imbalance here are some techniques to be considered:-\n",
    "\n",
    "- Resampling: Either oversampling the minority class (creating more samples of the minority class) or undersampling the majority class (removing samples from the majority class).\n",
    "\n",
    "- Class weights: Assigning higher weights to the minority class during model training to give it more importance.\n",
    "\n",
    "- Synthetic data generation: Generating synthetic samples for the minority class using techniques like SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "\n",
    "- Different algorithms: Using algorithms that are less sensitive to class imbalance, such as decision trees or random forests.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e2696",
   "metadata": {},
   "source": [
    "I will explore two options\n",
    "- Resampling\n",
    "- Class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebb390",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "Resampling is a technique used to address class imbalance by either oversampling the minority class (creating more samples of the minority class) or undersampling the majority class (removing samples from the majority class). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e160f1",
   "metadata": {},
   "source": [
    "# Oversampling the minority class (i.e Sentiment = class -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b87247",
   "metadata": {},
   "source": [
    "# LSTM for sentiment analysis\n",
    "The steps to be considered include:-\n",
    "\n",
    "- Preprocess the text data- i am using already preprocessed text data\n",
    "- Tokenize the preprocessed data\n",
    "- Prepare data for training\n",
    "- split the data into training and test set\n",
    "- define and train the LSTM model\n",
    "- Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4e92efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dbb96aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the preprocessed text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df2['preprocessed_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df2['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "57909e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 37\n"
     ]
    }
   ],
   "source": [
    "#Find the maximum sequence length\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "\n",
    "print(\"Maximum sequence length:\", max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "93430f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the data for training\n",
    "max_len = 37  # Max sequence length\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "y = df2['sentiment_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8cf46136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ... 9052 1724    2]\n",
      " [   0    0    0 ...   12  179 1069]\n",
      " [   0    0    0 ...  369    6 2984]\n",
      " ...\n",
      " [   0    0    0 ...  954 2414   49]\n",
      " [   0    0    0 ... 1359   36   66]\n",
      " [   0    0    0 ...   99  104 1321]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6b87777b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 37)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b7baa1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 ... 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cd56dee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000,)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ab82c30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1280000, 37), (320000, 37), (1280000,), (320000,))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9edf309c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dtype: int32\n",
      "y_train dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train dtype:\", X_train.dtype)\n",
    "print(\"y_train dtype:\", y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0d02fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and train the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))  # Output layer with 3 units for 3 sentiment classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e85247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1312/10000 [==>...........................] - ETA: 1:55:55 - loss: 0.1857 - accuracy: 0.9335"
     ]
    }
   ],
   "source": [
    "#Model compilation and training\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0fd9e616",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 17.9 GiB for an array with shape (1600000, 3000) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Prepare the data for training\u001b[39;00m\n\u001b[0;32m      9\u001b[0m max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3000\u001b[39m  \u001b[38;5;66;03m# Max sequence length\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m X \u001b[38;5;241m=\u001b[39m pad_sequences(sequences, maxlen\u001b[38;5;241m=\u001b[39mmax_len)\n\u001b[0;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtextblob_sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\data_utils.py:1120\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dtype_str:\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1115\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dtype` \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not compatible with `value`\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms type: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mYou should set `dtype=object` for variable length \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1118\u001b[0m     )\n\u001b[1;32m-> 1120\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull((num_samples, maxlen) \u001b[38;5;241m+\u001b[39m sample_shape, value, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sequences):\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:344\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[0;32m    342\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m asarray(fill_value)\n\u001b[0;32m    343\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m fill_value\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m--> 344\u001b[0m a \u001b[38;5;241m=\u001b[39m empty(shape, dtype, order)\n\u001b[0;32m    345\u001b[0m multiarray\u001b[38;5;241m.\u001b[39mcopyto(a, fill_value, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 17.9 GiB for an array with shape (1600000, 3000) and data type int32"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab45bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check shape of train and test df\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11124cc2",
   "metadata": {},
   "source": [
    "# LONG-SHORT-TERM MEMORY (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af84319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52b9a0",
   "metadata": {},
   "source": [
    "## Drop unused variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6de47",
   "metadata": {},
   "source": [
    "# LSTM (Long Short Term Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf98e59",
   "metadata": {},
   "source": [
    "# ONE-HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1db6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b903b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the sentiment_vader variable\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "sentiment_encoded = onehot_encoder.fit_transform(df[['sentiment_vader']])\n",
    "vader_df = pd.concat([df[['date']], pd.DataFrame(sentiment_encoded, columns=onehot_encoder.categories_[0])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a004fc",
   "metadata": {},
   "source": [
    "# Split the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5b6326f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1280000, 4), (320000, 4))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "467edfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d530f3d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(0, 1, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(0, 1, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Reshape into X=t and Y=t+1\u001b[39;00m\n\u001b[0;32m      2\u001b[0m look_back \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 3\u001b[0m trainX, trainY \u001b[38;5;241m=\u001b[39m create_dataset(train, look_back)\n\u001b[0;32m      4\u001b[0m testX, testY \u001b[38;5;241m=\u001b[39m create_dataset(test, look_back)\n",
      "Cell \u001b[1;32mIn[96], line 4\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[1;34m(dataset, look_back)\u001b[0m\n\u001b[0;32m      2\u001b[0m dataX, dataY \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;241m-\u001b[39mlook_back\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     a \u001b[38;5;241m=\u001b[39m dataset[i:(i\u001b[38;5;241m+\u001b[39mlook_back), \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     dataX\u001b[38;5;241m.\u001b[39mappend(a)\n\u001b[0;32m      6\u001b[0m     dataY\u001b[38;5;241m.\u001b[39mappend(dataset[i \u001b[38;5;241m+\u001b[39m look_back, \u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3809\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m   3810\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5923\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5924\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5925\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(0, 1, None), 0)"
     ]
    }
   ],
   "source": [
    "#Reshape into X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7e832",
   "metadata": {},
   "source": [
    "# Implement LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1599b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement LSTM model\n",
    "def create_dataset(X, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "        ys.append(X[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "TIME_STEPS = 10\n",
    "X_train, y_train = create_dataset(train_sentiment_scaled, TIME_STEPS)\n",
    "X_test, y_test = create_dataset(test_sentiment_scaled, TIME_STEPS)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model_lstm.add(LSTM(units=50))\n",
    "model_lstm.add(Dense(units=1))\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_lstm.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "lstm_predictions_scaled = model_lstm.predict(X_test)\n",
    "lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)\n",
    "\n",
    "# Evaluate the models\n",
    "arima_rmse = np.sqrt(mean_squared_error(test_sentiment, arima_predictions))\n",
    "lstm_rmse = np.sqrt(mean_squared_error(test_sentiment, lstm_predictions))\n",
    "\n",
    "print(\"ARIMA RMSE:\", arima_rmse)\n",
    "print(\"LSTM RMSE:\", lstm_rmse)\n",
    "\n",
    "# Make predictions for 1 day, 3 days, and 7 days ahead\n",
    "def forecast_sentiment(model, data, steps):\n",
    "    last_window = data[-TIME_STEPS:]\n",
    "    forecast = []\n",
    "    for _ in range(steps):\n",
    "        prediction = model.predict(last_window.reshape(1, -1, 1))[0][0]\n",
    "        forecast.append(prediction)\n",
    "        last_window = np.roll(last_window, -1)\n",
    "        last_window[-1] = prediction\n",
    "    return forecast\n",
    "\n",
    "# Forecast sentiment using ARIMA\n",
    "arima_forecast_1day = model_arima_fit.forecast(steps=1)[0][0]\n",
    "arima_forecast_3day = model_arima_fit.forecast(steps=3)[0][-1]\n",
    "arima_forecast_7day = model_arima_fit.forecast(steps=7)[0][-1]\n",
    "\n",
    "# Forecast sentiment using LSTM\n",
    "lstm_forecast_1day = forecast_sentiment(model_lstm, test_sentiment_scaled[-TIME_STEPS:], 1)\n",
    "lstm_forecast_3day = forecast_sentiment(model_lstm, test_sentiment_scaled[-TIME_STEPS:], 3)[-1]\n",
    "lstm_forecast_7day = forecast_sentiment(model_lstm, test_sentiment_scaled[-TIME_STEPS:], 7)[-1]\n",
    "\n",
    "print(\"ARIMA 1-day forecast:\", arima_forecast_1day)\n",
    "print(\"ARIMA 3-day forecast:\", arima_forecast_3day)\n",
    "print(\"ARIMA 7-day forecast:\", arima_forecast_7day)\n",
    "print(\"LSTM 1-day forecast:\", lstm_forecast_1day)\n",
    "print(\"LSTM 3-day forecast:\", lstm_forecast_3day)\n",
    "print(\"LSTM 7-day forecast:\", lstm_forecast_7day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea9cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c675ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Load the dataset\n",
    "# Assuming df contains at least two columns: 'date' and 'sentiment'\n",
    "\n",
    "# Preprocess the data\n",
    "# Ensure 'date' column is in datetime format\n",
    "\n",
    "# Implement ARIMA model\n",
    "def train_arima_model(data):\n",
    "    model_arima = ARIMA(data, order=(5,1,0))\n",
    "    model_arima_fit = model_arima.fit(disp=0)\n",
    "    return model_arima_fit\n",
    "\n",
    "def forecast_arima(model, steps):\n",
    "    forecast = model.forecast(steps=steps)[0]\n",
    "    return forecast\n",
    "\n",
    "# Implement LSTM model\n",
    "def create_dataset(X, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "        ys.append(X[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def train_lstm_model(data, time_steps=10):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    X, y = create_dataset(data_scaled, time_steps)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
    "    model_lstm.add(LSTM(units=50))\n",
    "    model_lstm.add(Dense(units=1))\n",
    "\n",
    "    model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model_lstm.fit(X, y, epochs=100, batch_size=32, verbose=0)\n",
    "    \n",
    "    return model_lstm, scaler\n",
    "\n",
    "def forecast_lstm(model, scaler, data, steps, time_steps=10):\n",
    "    forecast = []\n",
    "    last_window = data[-time_steps:]\n",
    "    for _ in range(steps):\n",
    "        prediction = model.predict(last_window.reshape(1, -1, 1))[0][0]\n",
    "        forecast.append(prediction)\n",
    "        last_window = np.roll(last_window, -1)\n",
    "        last_window[-1] = prediction\n",
    "    forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1))\n",
    "    return forecast\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the dashboard\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='forecast-graph'),\n",
    "    html.Label('Select Model:'),\n",
    "    dcc.Dropdown(\n",
    "        id='model-dropdown',\n",
    "        options=[\n",
    "            {'label': 'ARIMA', 'value': 'arima'},\n",
    "            {'label': 'LSTM', 'value': 'lstm'}\n",
    "        ],\n",
    "        value='arima'\n",
    "    ),\n",
    "    html.Label('Select Forecast Period:'),\n",
    "    dcc.Dropdown(\n",
    "        id='period-dropdown',\n",
    "        options=[\n",
    "            {'label': '1 Day', 'value': 1},\n",
    "            {'label': '3 Days', 'value': 3},\n",
    "            {'label': '7 Days', 'value': 7}\n",
    "        ],\n",
    "        value=1\n",
    "    )\n",
    "])\n",
    "\n",
    "# Define callback to update the graph based on user input\n",
    "@app.callback(\n",
    "    Output('forecast-graph', 'figure'),\n",
    "    [Input('model-dropdown', 'value'),\n",
    "     Input('period-dropdown', 'value')]\n",
    ")\n",
    "def update_graph(selected_model, forecast_period):\n",
    "    if selected_model == 'arima':\n",
    "        model = train_arima_model(df['sentiment'])\n",
    "        forecast = forecast_arima(model, forecast_period)\n",
    "    elif selected_model == 'lstm':\n",
    "        lstm_model, scaler = train_lstm_model(df['sentiment'])\n",
    "        forecast = forecast_lstm(lstm_model, scaler, df['sentiment'], forecast_period)\n",
    "    \n",
    "    # Generate x-axis values (dates)\n",
    "    dates = pd.date_range(start=df['date'].iloc[-1], periods=forecast_period + 1)[1:]\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = {\n",
    "        'data': [\n",
    "            {'x': dates, 'y': forecast, 'type': 'line', 'name': 'Forecast'}\n",
    "        ],\n",
    "        'layout': {\n",
    "            'title': f'{selected_model.upper()} Forecast for {forecast_period} Days',\n",
    "            'xaxis': {'title': 'Date'},\n",
    "            'yaxis': {'title': 'Sentiment'}\n",
    "        }\n",
    "    }\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8fd437",
   "metadata": {},
   "source": [
    "# TIME SERIES FORECASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ead0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
